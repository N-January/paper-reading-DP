## 计算机视觉中的多视图几何

[TOC]

### 第二章

#### 2.2 2D射影平面

##### 2.2.1 点与直线

一、齐次坐标

在n维坐标中额外添加一个坐标（该坐标一般为1，不能为0），变成n+1维。则该n+1维便是n维坐标的齐次坐标。

二、直线的齐次表示

平面上的一条直线$ ax+by+c = 0 $  ，可以用向量${(a,b,c)}^T$表示。但是直线和向量不是一一对应的，因为对任何非零常数$k$，直线$ax+by+c=0$和直线$(ka)x+(kb)y+(kc)=0$相同。因此，对任何非零常数$k$，向量${(a,b,c)}^T$和向量$k{(a,b,c)}^T$表示同一直线。由此可得这两个向量是等价的，这种等价关系下的向量称为齐次向量。

三、点的齐次表示

一个点$\bf{x} = (x_1^{'}，x_2^{'})$的任何齐次向量的表示形式为$\bf{X}={(x_1,x_2,x_3)}^T$ ，其中$\bf{x_1^{'} }= x_1\div x_3,x_2^{'} = x_2\div x_3$ 。 如果点$\bf{x}$表示$\bf{IR}^2$中的一点$\bf{(x_1/x_3,x_2/x_3)}^T$。则点$\bf{X}={(x_1,x_2,x_3)}^T$ 作为齐次向量同样也是$\bf{IR}^2$的元素。

四、三个结论

(1) 点$\bf{x}$在直线$\bf{l}$上当且仅当$\bf{x^Tl=0}$

(2) 两直线$\bf{l}$和$\bf{l^{'}}$的交点是点 $\bf{x = l\times l^{'}}$

(3) 过两点$\bf{x}$和$\bf{x^{'}}$的直线是$\bf{l = x\times x^{'}}$

##### 2.2.2 理想点与无穷远直线

一、理想点

二维向量$\bf{x} = (x_1^{'}，x_2^{'})$的齐次向量为$\bf{x} = {(x_1,x_2,x_3)}^T$ 。当$x_3\neq0$时，齐次向量$\bf{x} = {(x_1,x_2,x_3)}^T$对应的$\bf{IR}^2$中的有限点（有确定的大小）。把$x_3=0$的点加入到$\bf{IR}^2$，所扩展的空间是所有齐次三维向量的几何，称为射影空间$\bf{IP}^2$。最后坐标为$x_3=0$的点$\bf{x} = {(x_1,x_2,0)}^T$称为理想点。

二、无穷远直线

上述的理想点的集合${(x_1,x_2,0)}^T$ 在由向量$\bf{l_\infty}={(0,0,1)}^T$表示的一条直线上，则该直线为无穷远直线



##### 2.2.3 二次曲线与对偶二次曲线

一、齐次二次曲线的表达形式

（1）二次多项式表达：
$$
ax_1^2+bx_1x_2+cx_2^2+dx_1x_3+ex_2x_3+fx_3^2 = 0 \tag{2.1}
$$
（2）矩阵形式
$$
\mathbf{x^TCx} = 0   \tag{2.2}
$$
二、齐次二次曲线系数矩阵
$$
\mathbf{C} = \begin{bmatrix}a & b/2 & d/2 \\ b/2 & c & e/2 \\ d/2 & e/2 & f \end{bmatrix}  \tag{2.3}
$$
三、二次曲线的切线表示

​	与二次曲线$\mathbf{C}$相切于点$\mathbf{x}$的直线$\mathbf{l}$由$\mathbf{l = Cx}$确定

四、对偶二次曲线

​	上述一、二、三中提到的二次曲线，实际上是==**点**==  二次曲线 。本次提出的==**对偶**==二次曲线实际上就是==**线**==二次曲线。该二次曲线也是由一个$3\times3$矩阵表示，记作$\mathbf{C^*}$。二次曲线$\mathbf{C}$的切线$\mathbf{l}$满足：
$$
\mathbf{l^TC^*l = 0} \tag{2.4}
$$
其中$\mathbf{C^*}$表示$\mathbf{C}$的伴随矩阵（伴随矩阵见附录4中的A4.2）

四、退化二次曲线（点二次曲线）

​	如果矩阵$\mathbf{C}$是非满秩的，那么该二次曲线称为退化二次曲线。因为矩阵$\mathbf{C}$是$3\times3$的矩阵，因此当非满秩时，共有两种情况，一是秩为2，即二次曲线包含两条直线；一是秩为1，即二次曲线包含一条重线。



#### 2.4 变换的层次

一、不变量

​	一种代数方法通过特定方法的变换，可以变换成另外一种代数方法。这种变换中保持不变的参数就是不变量。

##### 2.4.1 等距变换

一、概念

​	等距变换是在欧氏空间中进行旋转平移，等距变换是刚体的运动模型，即没有任何畸变，只有位置和角度的变化。

二、公式
$$
\begin{pmatrix}x^{'} \\ y^{'} \\1 \end{pmatrix} = \begin{bmatrix}\xi cos\theta & -sin\theta&t_x\\\xi sin\theta & cos\theta & t_y  \\0 &0&1 \end{bmatrix}\begin{pmatrix}x \\ y \\1 \end{pmatrix}   \tag{2.5}
$$
三、 不变量

​	不变量有长度，角度和面积

四、自由度

​	有三个自由度

##### 2.4.2 相似变换

一、概念

​	相似变换是一个等距变换和一个均匀缩放的复合。

二、公式

​	当欧式变换与缩放复合（即没有反射）时，相似变换的矩阵表示为：
$$
\begin{pmatrix}x^{'} \\ y^{'} \\1 \end{pmatrix} = \begin{bmatrix}s cos\theta & -ssin\theta&t_x\\s sin\theta & scos\theta & t_y  \\0 &0&1 \end{bmatrix}\begin{pmatrix}x \\ y \\1 \end{pmatrix}   \tag{2.6}
$$
三、 不变量

​	不变量有角度、长度的比率、面积的比率

四、自由度

​	比欧式变换多了一个缩放自由度，有四个自由度



##### 2.4.3 仿射变换

一、概念

​	仿射变换是一个非奇异线性变换与一个平移变换的复合

二、公式

​	矩阵表示如下：
$$
\begin{pmatrix}x^{'} \\ y^{'} \\1 \end{pmatrix} = \begin{bmatrix}a_{11} & a_{12}&t_x\\a_{21} & a_{22} & t_y  \\0 &0&1 \end{bmatrix}\begin{pmatrix}x \\ y \\1 \end{pmatrix}   \tag{2.7}
$$
三、 不变量

​	不变量有平行线、平行线的长度比、面积比

四、自由度

​	有六个自由度



##### 2.4.3 射影变换

一、概念

​	射影变换是在射影空间下的变换，是射影空间到它自身的一种满足下列条件的可逆映射$h$:三点$\mathbf{x_1,x_2,x_3}$共线当且仅当$h(\mathbf{x_1}),h(\mathbf{x_2}),h(\mathbf{x_3})$也共线。

二、公式

​	矩阵表示如下：
$$
\mathbf{x{'}} = \begin{bmatrix}mathbf{A} &\mathbf{t}\\\mathbf{v^T} & v  \end{bmatrix}\mathbf{x}   \tag{2.7}
$$
三、 不变量

​	不变量有四个共线点的交比、直线上长度的交比

四、自由度

​	有九个自由度



------



### 第四章

#### 4.1 直接线性变换（DLT）算法

一、什么是2D单应

​	给定$\mathbf{IP}^2$中的点集$\mathbf{x}_i$和同在$\mathbf{IP}^2$中的点集$\mathbf{x}_i^{'}$，计算把每一点$\mathbf{x}_i$映射到对应点$\mathbf{x}_i^{'}$的射影变换。在实际的情景中，点$\mathbf{x}_i$和点$\mathbf{x}_i^{'}$是在两幅图像（或同一幅图像）中的点，每幅图像都视为一张射影平面$\mathbf{IP}^2$。2D单应就是点集$\mathbf{x}_i$和点集$\mathbf{x}_i^{'}$相互转换时的矩阵，即2.4中的变换矩阵$\bf{H}$。

二、测量数

​	测量数，就是我们需要求出多少个未知数。在二维平面中，单应性矩阵$\mathbf{H}$是一个$3\times 3$的矩阵，因此一共有9个元素。但是这9个元素，我们可以把最后一个元素当作一个尺度因子忽略掉。因此，单应性矩阵$\mathbf{H}$的测量数应该是9-1=8。那么求8个未知数，至少需要8个点，即4组点对。每组点对中的两个点分别来自两幅图像（或同一幅图像）中的点。这组点的自由度为2，即需要求出2个测量数。一组点对可以求出两个测量数，那么4组点便可以求出8个测量数，也就是单应性矩阵$\bf{H}$的测量数。

三、DLT算法

​	从2D到2D的转换中，我们给出变换方程$\mathbf{x}_i^{'} = H\mathbf{x}_i$,由向量本身叉乘自己为零可知，$\mathbf{x}_i^{'} \times H\mathbf{x}_i = 0$。

​	如果把矩阵$H$的第$j$行记为$\mathbf{h}^{jT}$，则
$$
H\mathbf{x}^i = \begin{pmatrix}\mathbf{h}^{1T}\mathbf{x}_i \\ \mathbf{h}^{2T}\mathbf{x}_i \\ \mathbf{h}^{3T}\mathbf{x}_i \end{pmatrix}  \tag{4.1}
$$
​	记$\mathbf{x}^{'} = (x^{'}_i,y^{'}_i,w^{'}_i)^T$，那么叉乘$\mathbf{x}_i^{'} \times H\mathbf{x}_i$可以表示如下：
$$
\mathbf{x}_i^{'} \times H\mathbf{x}_i = \begin{pmatrix} y^{'}_i\mathbf{h}^{3T}\mathbf{x}_i -  w^{'}_i\mathbf{h}^{2T}\mathbf{x}_i  \\ w^{'}_i\mathbf{h}^{1T}\mathbf{x}_i -  x^{'}_i\mathbf{h}^{3T}\mathbf{x}_i \\ x^{'}_i\mathbf{h}^{2T}\mathbf{x}_i - y^{'}_i\mathbf{h}^{1T}\mathbf{x}_i\end{pmatrix}   \tag{4.2}
$$


​	当$j = 1,2,3$时，任取公式4.1中的一个元素$\mathbf{h}^{jT}\mathbf{x}_i$，对其展开可得
$$
\begin{pmatrix} h^j_1 \\ h^j_2 \\ h^j_3\end{pmatrix} \begin{pmatrix} x_i & y_i & w_i\end{pmatrix} = \begin{pmatrix} x_i \\ y_i \\ w_i\end{pmatrix} \begin{pmatrix} h^j_1 & h^j_2 & h^j_3\end{pmatrix} \tag{4.3}
$$
​	即
$$
\mathbf{h}^{jT}\mathbf{x}_i = \mathbf{x}_i^T\mathbf{h}^{j} \tag{4.4}
$$
​	由4.4公式，我们可以得到
$$
\begin{bmatrix}0^T & -w^{'}_i\mathbf{x^T}_i & y^{'}_i\mathbf{x^T}_i \\ w^{'}_i\mathbf{x^T}_i &0^T   & -x^{'}_i\mathbf{x^T}_i \\ -y^{'}_i\mathbf{x^T}_i & x^{'}_i\mathbf{x^T}_i &0^T  \end{bmatrix} \begin{pmatrix}\mathbf{h}^1 \\ \mathbf{h}^2 \\\mathbf{h}^3 \end{pmatrix} = \mathbf{0}  \tag{4.5}
$$
​	公式4.5中的$\begin{bmatrix}0^T & -w^{'}_i\mathbf{x^T}_i & y^{'}_i\mathbf{x^T}_i \\ w^{'}_i\mathbf{x^T}_i &0^T   & -x^{'}_i\mathbf{x^T}_i \\ -y^{'}_i\mathbf{x^T}_i & x^{'}_i\mathbf{x^T}_i &0^T  \end{bmatrix}$矩阵的秩为2，则我们可以用如下公式表示：
$$
\begin{bmatrix}0^T & -w^{'}_i\mathbf{x^T}_i & y^{'}_i\mathbf{x^T}_i \\ w^{'}_i\mathbf{x^T}_i &0^T   & -X^{'}_i\mathbf{x^T}_i   \end{bmatrix} \begin{pmatrix}\mathbf{h}^1 \\ \mathbf{h}^2 \\\mathbf{h}^3 \end{pmatrix} = \mathbf{0}  \tag{4.5}
$$


​	它可以写成
$$
A_i\mathbf{h} = 0 \tag{4.6}
$$
​	其中，$A_i$是$2\times 9$的矩阵。

公式4.6为一组点的表示，如果要求$\mathbf{H}$的值，则需要四组公式，即$i = 1,2,3,4$。

我们可以用奇异值分解算法（SVD）或者最小二乘法进行求解。

四、用最小二乘法求线性方程组$\mathbf{Ax = b}$的解

​	当$\mathbf{A}$为可逆矩阵时，将线性方程组两边分别左乘$\mathbf{A}^T$，得到
$$
\mathbf{A^TAx = A^Tb} \tag{4.7}
$$
​	再将公式4.7两边同时乘以$\mathbf{(A^TA)}^{-1}$，得到
$$
\mathbf{x = (A^TA)^{-1}A^Tb}  \tag{4.8}
$$


​	即可到$\mathbf{x}$的解。

五、用SVD求线性方程组的最小二乘解

​		$\mathbf{SVD}$：给定一个方阵$\bf{A}$，$\mathbf{SVD}$把$\bf{A}$分解为$\bf{A = UDT^T}$，其中$\bf{U}$与$\bf{V}$是正交矩阵，而$\bf{D}$是元素为非负的一个对角矩阵。特别需要注意：$\bf{U}$具有保范性质，即可实际验证，对任何向量$\bf{x}$都有$\begin{Vmatrix}\bf{Ux} \end{Vmatrix} = \begin{Vmatrix}\bf{U} \end{Vmatrix}$。

​		已知$\mathbf{Ax = b}$，通过SVD求方程组的最小二乘解：

答：由$\mathbf{Ax = b}$得$\mathbf{Ax-b = 0}$，则只需$\begin{Vmatrix} \mathbf{Ax-b} \end{Vmatrix}$得到最小值即可。	

​		由SVD可得$\begin{Vmatrix} \mathbf{Ax-b} \end{Vmatrix} = \begin{Vmatrix} \mathbf{UDV^Tx-b} \end{Vmatrix}$，我们只需求得该公式的最小值向量$\bf{x}$即可。由于正交变换的保范性质，我们要最小化的量是$ \begin{Vmatrix} \mathbf{UDV^Tx-b} \end{Vmatrix}= \begin{Vmatrix} \mathbf{DV^Tx-U^Tb} \end{Vmatrix}$。记$\bf{y = V^Tx}$和$\bf{b{'} = U^Tb}$，问题变成最小化$ \begin{Vmatrix}\bf{Dy - b^{'} }\end{Vmatrix}$ ,其中$\bf{D}$为$m\times n$矩阵并且对角线以外的元素为零。这个方程组的形式是（搞定( •̀ ω •́ )✧）
$$
\begin{bmatrix}d_1 \\ & d_2 \\ & & \cdots \\ &&& d_n \\ \hline \\ && 0\end{bmatrix}  \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n\end{pmatrix} = \begin{pmatrix}b^{'}_1 \\ b^{'}_2 \\ \vdots \\b^{'}_n \\ \hline \\ b^{'}_{n+1} \\ \vdots \\b^{'}_m\end{pmatrix}  \tag{4.9}
$$




显然，离$\bf{b^{'}}$最近的$\bf{\bf{Dy}}$是向量$(b^{'}_1,b^{'}_2,…,b^{'}_n,0,…,0)^T$并通过令$y^{'}_i = b^{'}_i\div d_i(i = 1,…,n)$而得到。注意假定$\bf{A}$的秩为$n$保证了$d_i\neq0$。最后由$\bf{x=Vy}$求出$\bf{x}$。整个算法是

==目标==

​	==求$m\times n$方程组$\mathbf{Ax = b}$的最小二乘解，其中$m>n$，并且$rangA=n$。==

==算法==

​	==（1）求SVD：$\bf{A = UDV^T}$。==

​	==（2）令$\bf{b{'} = U^Tb}$。==

​	==（3）求由$y^{'}_i = b^{'}_i\div d_i$定义的$\bf{y}$，其中$d_i$是$\bf{D}$的第$i$个对角元素。==

​	==（4）所求解为$\bf{x=Vy}$==

##### 4.1.1 超定解

一、超定解

​	当二维的齐次方程组给出的点的组数多于四组时，齐次方程组$\bf{Ah=0}$是超定的。此时所求出的解便是超定解。

二、$\begin{Vmatrix} \mathbf{h} \end{Vmatrix}=1$的作用

​	$\begin{Vmatrix} \mathbf{h} \end{Vmatrix}=1$的作用有两个，一个是可以确定缩放因子的大小，二是因为我们求超定解的时候，不需要零解，为了避开$\bf{h=0}$的解，加上$\begin{Vmatrix} \mathbf{h} \end{Vmatrix}=1$这个约束条件。

三、超定方程组的最小二乘解

​	我们假定超定方程组为$\mathbf{Ax = 0}$，由于所有的点不一定都是精确的，一般都包含噪声，因此这样的方程组一般不存在精确的解。那么我们一般需要求出它的最小二乘解。这里的$\bf{x}$就是我们经常说的$\bf{h}$，则我们可以将超定解简述为：

​	*** 求使$\begin{Vmatrix} \mathbf{Ax} \end{Vmatrix}=1$最小化并满足$\begin{Vmatrix} \mathbf{x} \end{Vmatrix}=1$的最小二乘解$\bf{x}$ **

该问题的的解法为：首先通过SVD算法，令$\bf{A = UDT^T}$，由于$\bf{U}$的保范性质，我们可以得到$ \begin{Vmatrix} \mathbf{UDV^Tx} \end{Vmatrix}= \begin{Vmatrix} \mathbf{DV^Tx} \end{Vmatrix}$和$ \begin{Vmatrix} \mathbf{x} \end{Vmatrix}= \begin{Vmatrix} \mathbf{V^Tx} \end{Vmatrix}$。因此，我们只需要在条件$ \begin{Vmatrix} \mathbf{x} \end{Vmatrix}= \begin{Vmatrix} \mathbf{V^Tx} \end{Vmatrix}=1$下最小化$\begin{Vmatrix} \mathbf{DV^Tx} \end{Vmatrix}$。我们令$\bf{y = V^Tx}$，则问题变为在条件$\begin{Vmatrix} \mathbf{y} \end{Vmatrix}=1$下最小化$\begin{Vmatrix} \mathbf{Dy} \end{Vmatrix}$。由$\bf{D}$是对角元素按降序排列的一个对角矩阵，推出该问题的解是$\bf{y=(0,0,\cdots,0,1)^T}$，它具有一个非零元素1并在最后的位置上。最后注意的是$\bf{x = Vy}$的解就是$\bf{V}$的最后一列。而$\bf{V}$的最后一列就是$\bf{AA^T}$最小特征值的特征向量。

四、超定方程组的DLT算法（不含归一化）

==目标==

​	==给定$n\geq4$组2D到2D点对，确定2D单应性矩阵$\bf{H}$使得$\mathbf{x}_i^{'} = H\mathbf{x}_i$。==

==算法==

​	==（1）根据每组对应点对和公式4.5计算矩阵$\bf{A_i}$。==

​	==（2）把n个$2\times 9$的矩阵$\bf{A_i}$组合成$2n\times 9$的矩阵$\bf{A}$。==

​	==（3）求$\bf{A}$的SVD。根据超定方程组的最小二乘解，我们可以得出向量$\bf{h}$的解就是最小特征值得特征向量。具体内容详见第三部分 超定方程组的最小二乘解。==

​	==（4）根据（1）（2）（3），以此求出$\bf{h_1,h_2,h_3}$，最终由$\bf{h=\begin{pmatrix} h_1 \\ h_2\\h_3 \end{pmatrix}}$得到矩阵$\bf{H}$。==

##### 4.1.2 非齐次解

##### 4.1.3 退化配置

##### 4.1.4 由线和其他实体求解

4.1.2-4.1.4了解就行

#### 4.2 不同的代价函数

##### 4.2.1 代数距离

​	一、什么是代数距离

​	由DLT算法可知，如果想要求出二维的线性变换，需要四组对应点对$\bf{x_i\leftrightarrow x_i^{'}}$,根据公式4.6，我们可以得到每组点对的线性变换函数$A_i\mathbf{h}=0$，记$\epsilon_i = A_i\mathbf{h}$称为残差向量，将四组点对的残差向量累计成总误差向量$\bf{\epsilon}$,则该总误差向量的二范数便是***代数距离***：
$$
d_{alg}(\bf{x_i^{'},Hx_i})^2 = \begin{Vmatrix}\epsilon_i\end{Vmatrix}^2=\begin{Vmatrix}\begin{bmatrix}0^T & -w_i^{'}\mathbf{x_i^T} & y_i^{'}\mathbf{x_i^T} \\w_i^{'}\mathbf{x_i^T} & 0^T & -x^{'}\mathbf{x_i^T} \end{bmatrix} \mathbf{h}\end{Vmatrix}^2 \tag{4.10}
$$


二、代数距离的优缺点：

​	代数距离的优点：适当选择归一化最小化代数距离的方法可以给出非常好的结果，而且代数距离的解为线性解，计算代价小 。

​	代数距离的缺点：代数距离最小化的量没有几何或统计上的意义。

##### 4.2.2 几何距离

一、几何距离

​	在一幅图像上有一点$x$,向量$\bf{x}$表示***测量得到***的图像坐标点；向量$\bf{\hat{x}}$表示点的估计值；向量$\overline{\bf{x}}$表示点的真值。那么几何距离便是最小化图像坐标中测量值和估计值的差，这个差就是测量值和估计值两点之间的欧式距离。

​	然后我想再多讲一点儿，为下面的重投影误差做铺垫，可能有点儿绕，我尽量讲清楚

我们之前讲的2D到2D的转换，即两幅图像$\bf{A、B}$对应点之间的转换。假设图像$\bf{A}$中的点为$x$，其真值向量为$\overline{\bf{x}}$，则再第二幅图象$\bf{B}$上的对应测量点为$\bf{x^{'}}$。如果没有误差的话，公式应该是这样的$\bf{x}^{'}=\mathbf{H\overline{\bf{x}}}$ 。但是它们之间是有误差的，该误差便是向量$\bf{x}^{'}$和$\mathbf{H\overline{\bf{x}}}$之间的欧氏距离，记为：
$$
\sum_id(\mathbf{x}^{'}_i,\mathbf{H\overline{\mathbf{x}}}_i)^2 \tag{4.11}
$$
该误差就是转移误差。

​	在实际图像测量误差过程中，不仅是一幅图像的误差，而是两幅图像都产生误差。公式4.11表示的一幅图像的误差，那么如何表示两幅图像之间的转移误差呢，我们可以这样构造误差函数，即同时考虑前向变换矩阵$\bf{H}$和后向变换矩阵$\bf{H}^{'}$，并把这两种变换对应的几何误差累加，公式如下所示：
$$
\sum_id(\mathbf{x}_i,\mathbf{H^{-1}\mathbf{x}^{'}}_i)^2+d(\mathbf{x}^{'}_i,\mathbf{H\mathbf{x}}_i)^2  \tag{4.12}
$$
​	其中第一项是第一幅图像的转移误差，第二项是第二幅图的转移误差。由于是两幅图像相互之间的误差，因此该误差称为对称转移误差

二、几何距离与代数距离的区别

假设$\mathbf{x}=(x,y,w)$是测量值，$\hat{\mathbf{x}} = (\hat{x},\hat{y},\hat{w})$是估计值。	

几何距离求的是测量值和估计值之间的欧式距离，即：
$$
d(\mathbf{x},\hat{\mathbf{x}})=((x/w-\hat{x}/\hat{w})^2+(y/w-\hat{y}/\hat{w})^2)^{1/2}
							  =d_{alg}(x,\hat{x})/\hat{w}w \tag{4.13}
$$
代数距离求得是测量值和估计值之间得叉乘，即：
$$
d_{alg}(\mathbf{x},\hat{\mathbf{x}})^2 = (y\hat{w}-w\hat{y})^2+(w\hat{x}-x\hat{w})^2 \tag{4.14}
$$
因此，几何距离与代数距离相关，但不相等。只有在$\hat{w} = w = 1$的时候，这两个距离是相等的。

##### 4.2.3 重投影误差

一、重投影误差

​	两幅图像之间进行转换时，总会有误差。这个误差一般是测量误差，我们需要对这些误差做校正。在公式4.11是对第二幅图象上的测量值与真值的校正。在这里为了得到完全的匹配点集，有必要在第二幅图上对测量值与估计值之间进行校正。

​	在这里，我们找到一个单应矩阵$\mathbf{\hat{H}}$，使得$\hat{\mathbf{x}}_i = \mathbf{\hat{H}}\hat{\mathbf{x}}_i^{'}$，即点$\hat{\mathbf{x}}_i$和$\hat{\mathbf{x}}_i^{'}$完全匹配，以最小化总的误差函数。
$$
\sum_id(\mathbf{x}_i,\hat{\mathbf{x}}_i)^2+(\mathbf{x}_i^{'},\hat{\mathbf{x}}_i^{'})^2~~~~~~  s.t. ~~\hat{\mathbf{x}}_i^{'} = \mathbf{\hat{H}}\hat{\mathbf{x}}_i^{'} ~~\forall i  \tag{4.15}
$$
​	这里的$d(\mathbf{x},\hat{\mathbf{x}})^2$所采用的是几何距离公式。这个公式的物理意义是我们先由$\mathbf{x}_i\leftrightarrow \mathbf{x}_i^{'}$估计出世界平面的点$\mathbf{\hat{X}}_i$，然后把它***重投影***到估计上认为是完全匹配对应的$\mathbf{\hat{x}}_i\leftrightarrow \mathbf{\hat{x}}_i^{'}$上。



![重投影误差](E:\学习\和WK一起快乐读书\12.12\Pic\重投影误差.jpg)

如图为对称转移误差和重投影误差在估计单应性矩阵时的比较。点$\bf{x}$和$\bf{x}^{'}$是测量得到（有噪声）的点。根据估计的单应矩阵，点$\bf{x}^{'}$和$\bf{Hx}$不完全对应。但是估计的点$\hat{\mathbf{x}}$和$\hat{\mathbf{x}}^{'}$，$\hat{\mathbf{x}} = \mathbf{\hat{H}}\hat{\mathbf{x}}^{'}$完全对应。令$d(\bf{x},\bf{y})$表示$\bf{x}$和$\bf{y}$的欧氏图像距离，则对称转移误差是$d(\mathbf{x}_i,\mathbf{H^{-1}\mathbf{x}^{'}}_i)^2+d(\mathbf{x}^{'}_i,\mathbf{H\mathbf{x}}_i)^2$ ；重投影误差是$d(\mathbf{x},\hat{\mathbf{x}})^2+(\mathbf{x}^{'},\hat{\mathbf{x}}^{'})^2$。



#### 4.3 统计代价函数和最大似然估计

一、铺垫

​	4.2节中主要讲了重投影误差，既然是误差，一般都会假设服从某种分布。根据这种分布便可以更好的消除误差。这里，我们假设图像测量误差遵循零平均各向同性高斯分布，本文里用概率密度函数（PDF）来表示（具体介绍在A2.1-P438）

​	若点的真值是$\overline {\mathbf{x}}$,则每个测量点$\bf{x}$的概率密度函数（PDF)是：
$$
Pr(\mathbf{x})=(\frac{1}{2\pi \sigma ^2})e^{-d(\mathbf{x},\overline {\mathbf{x}})^2/(2 \sigma ^2)}  \tag{4.16}
$$
二、单图像误差和最大似然法（ML）

​	首先考虑仅第二幅图像出现误差，则每点的误差都是独立分布的，获得点对应集$\overline{\mathbf{x}_i}\leftrightarrow \mathbf{x}_i^{'}$的概率就是它们单个PDF的乘积，其中$\overline {\mathbf{x}}_i$是第一幅图像的真值，即：
$$
Pr(\{\mathbf{x}_i^{'}\}|\mathbf{H})=\prod _i (\frac{1}{2\pi \sigma ^2})e^{-d(\mathbf{x}^{'}_i,\mathbf{H\overline{\mathbf{x}}}_i)^2/(2 \sigma ^2)} \tag{4.17}
$$ {  }
公式4.17还有一个对数似然，其实就是对公式4.17两边取对数。

​	其中单应性矩阵$\mathbf{H}$的***最大似然估计***$\mathbf{\hat{H}}$最大化这个对数似然，即最小化$\sum_id(\mathbf{x}^{'}_i,\mathbf{H\overline{\mathbf{x}}}_i)^2$——最小化几何误差函数4.11。

三、双图像误差和最大似然估计（ML）

​	双图像误差即考虑到两幅图像的误差，和公式4.16类似：
$$
Pr(\mathbf{x}_i,\mathbf{x}_i^{'}|\mathbf{H},\{\overline {\mathbf{x}}_i\})=\prod_i(\frac{1}{2\pi \sigma ^2})e^{-(d(\mathbf{x},\overline {\mathbf{x}})^2+d(\mathbf{x}^{'}_i,\mathbf{H\overline{\mathbf{x}}}_i)^2)/(2 \sigma ^2)} \tag{4.18}
$$
 该公式的***最大似然估计***是 $\sum_id(\mathbf{x}_i,\mathbf{H^{-1}\mathbf{x}^{'}}_i)^2+d(\mathbf{x}^{'}_i,\mathbf{H\mathbf{x}}_i)^2$ ，即最小化重投影误差函数4.12

#### 4.4 变换不变性和归一化

一、归一化的优缺点：

​	优点：归一化不仅提高了结果的精度，而且对初始数据归一化的算法将对任何尺寸缩放和坐标原点的选择不变。

​	缺点：暂无

二、什么是归一化：

计算均值坐标$p_{m}=[x_{m},y_{m}]^T$，其中（$N \ge \mathbf{4}$，$N$越多，噪声去除的效果越好）：
$$
x_m=\frac{1}{N}\sum_i^Nx_i,y_m=\frac{1}{N}\sum_i^Ny_i \tag{4.19}
$$
计算方差坐标：
$$
x_\sigma=\frac{1}{N}\sum_i^N(x_i-x_m)^2,~y_\sigma=\frac{1}{N}\sum_i^N(y_i-y_m)^2 \tag{4.20}
$$
然后去方差值中的最大值，记为$\sigma = max(x_\sigma,y_\sigma)$。

于是我们得到归一化矩阵$T$：
$$
T=\begin{bmatrix}\frac{1}{\sigma_{max}} & 0 & \frac{x_m}{\sigma_{max}}\\ 0 & \frac{1}{\sigma_{max}} & \frac{-y_m}{\sigma_{max}}\\ 0 & 0& 1\end{bmatrix}  \tag{4.21}
$$
同理我们得到$\tilde{p}_i$和$p_i$：
$$
\tilde{p}_i=\begin{bmatrix}\frac{1}{\sigma_{max}} & 0 & \frac{x_m}{\sigma_{max}}\\ 0 & \frac{1}{\sigma_{max}} & \frac{-y_m}{\sigma_{max}}\\ 0 & 0& 1\end{bmatrix} p_i \Rightarrow \begin{bmatrix}\frac{x_i-x_m}{\sigma_{max}} \\ \frac{y_i-y_m}{\sigma_{max}\\1}\end{bmatrix}  \tag{4.22}
$$
将$T$作用在每一个$p_i$上，得到$\tilde{p}_i$，于是我们完成了对点集$P$的归一化，同样的方法,我们可以得到$T^{'}$。

三、归一化后的DLT算法

==目标==

​	==给定$\bf{n}\ge4$组2D到2D的点对应$\{\mathbf{x}_i\leftrightarrow\mathbf{x}_i^{'}\}$，确定2D单应矩阵$\bf{H}$使得$\mathbf{x}_i^{'}=\mathbf{Hx}_i$。==

==算法==

​	==（1）**归一化**$\bf{x}$：计算一个只包括位移和缩放的相似变换$\bf{T}$，将点$\mathbf{x}_i$变到新的点集$\tilde{x}_i$，使得点$\tilde{x}_i$的形心位于原点$(0,0)^T$,并且它们到原点的平均距离是$\sqrt2$。==

​	==（2）**归一化**$\bf{x}^{'}$：针对第二幅图象上的点，类似地计算一个相似变换$\bf{T}^{'}$，将点$\mathbf{x}_i^{'}$变换到$\tilde{\mathbf{x}}_i^{'}$。==

​	==（3）**DLT**:将4.1.1中的算法应用于对应$\tilde{\mathbf{x}}_i\leftrightarrow\tilde{\mathbf{x}}_i^{'}$。==

​	==（4）**解除归一化：**令$\bf{H=T^{'-1}\tilde{H}T}$。==

四、反归一化

由第三部分可知反归一化公式为：
$$
\bf{H}=T^{'-1}\tilde{H}T  \tag{4.23}
$$

#### 4.7 鲁棒估计

一、什么是鲁棒估计

​	我们假定给出的对应集$\{\mathbf{x}_i\leftrightarrow \mathbf{x}_i^{'}\}$的误差服从高斯分布，但是在实际的误差中，总有某些点不服从高斯分布。这些点我们称为**野值**，这些**野值**会严重干扰单应矩阵的估计。此时，我们使用特定的方法，使得这些**野值**对单应矩阵的估计最小，即提高了对野值的鲁棒性，这种估计便是鲁棒估计。

##### 4.7.1 RANSAC

一、什么是RANSAC

​	RANSAC（RANdom SAmple Consensus），即随机采样一致性。以模拟直线为例，我们给出一组2D点的数据，总共$\bf{S}$个点，寻找一条直线，它能最小化点到直线的垂直距离的平方和（正交回归），并且所有有效点偏离该线的距离小于$t$，$t$为给定阈值。RANSAC算法是通过选择$\bf{s}（s\le S）$个点作为一个样本，模拟出一条直线，算出点在距离$\bf{t}$内的数目。遍历所有点，然后找出点在距离$\bf{t}$内的数目最大的直线，便是所求的直线。这种方法便是RANSAC。

二、什么是距离阈值

​	距离阈值便是第一部分中的给定阈值$\bf{t}$。

​	在实际过程中，距离阈值通常是根据经验确定。但是，当测量误差服从零均值和标准方差为$\sigma$的高斯分布，$\bf{t}$的值是可以算出来的。在此情况下，点的距离的平方$d^2_{\perp}$是高斯变量的平方和并服从一个自由度$m$的$\chi^2_m$分布，其中$m$等于模型的余维度。对于直线，余维度是1——仅测量到直线的垂直距离。如果模型是一个点，余维度是2，距离的平方是$x$和$y$测量误差的平方和。随机变量$\chi^2_m$的值小于$k^2$的概率由累积$\chi^2$分布$F_m(k^2)=\int_0^{k^2}\chi_m^2(\xi)d\xi$给出。这两个分布可参考A2.2—P438、P439。由该累积分布可知：
$$
\begin{cases}
内点 ~~~d^2_\perp<t^2\\
野点 ~~~ d^2_\perp\ge t^2
\end{cases}  ~~~~~~~~~且 t^2=F^{-1}_m(\alpha)\sigma^2  \tag{4.24}
$$
​	通常$\alpha$取值为0.95，即点为内点的概率为95%。它表明内点被错误排斥的概率仅是次数的5%。本书研究的各有关模型取$\alpha$=0.95，$t$的值在表4.1中列出：
$$
\begin{array}{c|c|c}
\hline
\text{余维度}m  &  \text{模型}  & t^2 \\
\hline
1 & \text{直线，基本矩阵} &3.84\sigma^2 \\
2 & \text{单应，摄像机矩阵} &5.99\sigma^2 \\
3 & \text{三焦点张量} & 7.81\sigma^2\\
\hline
\end{array}
$$
​																									表格4.1 点（对应）是内点的概率为$\alpha$=0.95时，距离阈值$t^2=F^{-1}_m(\alpha)\sigma^2$。

三、采样多少次为宜

​	假设采样次数为$\bf{N}$，只需保证由$\bf{s}$个点组成的随机样本中至少有一次没有野值的概率为$p$.通常$p$取为0.99。假定$\omega$是任意选择的数据点为内点的概率，那么$\epsilon=1-\omega$是其为野值的概率。那么至少需要$\bf{N}$次选择（每次$\bf{s}$个点），其中$(1-\omega^s)^{N}=1-p$。从而：
$$
N = log(1-p)/log(1-(1-\epsilon)^s) \tag{4.25}
$$
四、一致集多大为宜

​	根据经验，再给定野值的假定比例后，如果一致集大小接近期望属于该数据集的内点数时迭代就停止，即对$n$个数据，有$T=(1-\epsilon)n$。

五、自适应地决定采样次数

==$\bf{N}=\infty$,sample_count = 0==

==当$\bf{N}>sample_count$重复==

​		==—选取一个样本并计算内点数==

​		==—令$\epsilon=1-(内点数)/(总点数)$==

​		==—取$p=0.99$并由$\epsilon$及公式（4.24）求$N$==

​		==—sample_count加1==

==终止==

六、RANSAC算法流程

==$\underline{\text{目标}}$==

​	==一个模型与含有野值的数据集$S$鲁棒拟合==

==$\underline{\text{算法}}$==

​	==（1）随机地从$S$中选择$s$个数据点组成的一个样本作为模型的一个示例。==

​	==（2）确定在模型距离阈值$t$内的数据点集$S_i$，$S_i$称为采样的一致集并定义$S$的内点。==

​	==（3）如果$S_i$的大小（内点的数目）大于某个阈值$T$，用$S_i$的所有点重估计模型并结束。==

​	==（4）如果$S_i$的大小小于$T$，选择一个新的子集并重复上面的过程。==

​	==（5）经过$N$次试验选择最大一致集$S_i$，并用$S_i$的所有点重估计模型。==

##### 4.7.2 鲁棒最大似然估计

一、最大似然法在RANSAC算法中哪一步用到了

​	最大似然法在RANSAC算法的最优估计中用到了。RANSAC算法的最后一步是用所有的内点重新估计模型。重估计过程中，涉及到最小化ML（最大似然法）的代价函数。

二、鲁棒最大似然估计的鲁棒代价函数有几个，分别是什么

​	根据选择的点的类型不同，鲁棒代价函数有两种。第一种是仅在内点进行ML估计，此时的代价函数是$C=\sum_id^2_{\perp i}$；第二种是对所有点进行ML估计，此时的鲁棒代价函数是:
$$
D=\sum_i\gamma(d_{\perp i}) ~~~且\gamma(e)=\begin{cases}e^2~~~e^2<t^2 ~~~\text{内点}\\t^2~~~e^2\ge t^2 ~~~\text{野值}\end{cases} \tag{4.26}
$$

#### 4.8 单应的自动计算

一、RANSAC计算两幅图像之间的单应矩阵

==$\underline{目标}$==

​	==计算两幅图像间的2D单应==

==$\underline{算法}$==

​	==（1）**兴趣点**：在每一幅图像上计算兴趣点。==

​	==（2）**假设对应**：根据兴趣点灰度邻域的接近和相似，计算它们的匹配集。==

​	==（3）**RANSAC鲁棒估计**：重复$N$次采样，这里$N$按4.7.1节第四部分的自适应算法确定。==

​		==（a）选择由四组对应组成的一个随机样本并计算单应$\bf{H}$。==

​		==（b）对假设的每组对应，计算距离$d_\perp$。==

​		==（c）根据$d_\perp<t=\sqrt{5.99\sigma}$像素确定对应数，进而计算与$\bf{H}$一致的内点数。==

​			==选择具有最大内点数的$\bf{H}$。在数目相等时选择内点的标准方差最低的$\bf{H}$。==

​	==（4）**最有估计**：由划定为内点的所有对应重新估计$\bf{H}$，用A6.2-P466的Levenberg-Marquardt算法来最小化ML代价函数。==

​	==（5）**引导匹配**：用估计的$\bf{H}$去定义转移点位置附近的搜索区域，进一步确定兴趣点的对应最后两步可以重复直到对应的数目稳定为止。==

二、确定假设对应中用了什么方法进行匹配两幅图像的兴趣点

​	用了邻域灰度的近似度和相似度来匹配两幅图像的兴趣点。其中相似测量部分有两种方法，一是灰度差的平方和（简记SSD）；一是归一化（简记CC）。

三、距离测量中估计误差的方法有哪几种

​	估算误差有两种方法，一种是对称转移误差；一种是重投影误差。

四、选择样本时应该注意哪些问题

​	选择样本时应当注意退化的样本应当丢弃；组合的样本的点应该在整个图像上有合理的空间分布。

五、ML代价函数最小化采用了什么算法

​	采用了两种方式，一种方式是用A6.2-P466的Levenberg-Marquardt算法来最小化ML代价函数；一种方式是采用4.7.2中的最小化鲁棒ML代价函数同时估计单应和内点。后一种没有第一种计算快。

### 第六章摄像机模型

#### 6.1 有限摄像机

一、基本针孔模型

​	基本的针孔模型就是空间中一点到一张平面上的中心投影。令投影中心位于一个欧式坐标系的原点，并考虑$Z=f$的**图像平面**（或称为**聚焦平面**）。假设空间中一点的坐标$\mathbf{X}=(X,Y,Z)^T$，根据相似三角形，可以求出被映射到图像平面的点为$(f\mathbf{X}/\mathbf{Z},f\mathbf{Y}/\mathbf{Z},f)^T$。省略图像坐标中最后一维数后，从世界坐标系到图像坐标的中心投影是
$$
(\mathbf{X},\mathbf{Y},\mathbf{Z})^T \Rightarrow (f\mathbf{X}/\mathbf{Z},f\mathbf{Y}/\mathbf{Z})^T \tag{6.1}
$$
​	这是从3维欧式空间$IR^3$到2维欧氏空间$IR^2$的一个映射。

二、齐次坐标如何表示中心投影

​	公式6.1给出的是非齐次的表示中心投影公式，如何用齐次式表示，可以回顾**2.2.1节 齐次坐标 **，根据齐次坐标和公式6.1，我们不难得出如下结果：
$$
\begin{pmatrix}\mathbf{X}\\\mathbf{Y}\\\mathbf{Z}\\\mathbf{1}\end{pmatrix} \Rightarrow \begin{pmatrix}f\mathbf{X}\\f\mathbf{Y}\\\mathbf{Z}\end{pmatrix} = \begin{bmatrix}f&&&0\\&f&&0\\&&1&0\end{bmatrix}\begin{pmatrix}\mathbf{X}\\\mathbf{Y}\\\mathbf{Z}\\\mathbf{1}\end{pmatrix} \tag{6.2}
$$
​	上述表达式中的矩阵可以表示成$diag(f,f,1)[\bf{}I|0]$，其中$diag(f,f,1)$是对角矩阵，而$[\bf{}I|0]$表示矩阵分块成一个$3 \times 3$块（单位矩阵）加上一个列向量（这里是零向量）。这个矩阵是$3\times 4$齐次矩阵，我们用$P$表示，并称该矩阵为**齐次摄像机投影矩阵**。则6.2式可以简化为：
$$
\mathbf{x} = P\mathbf{X} \tag{6.3}
$$
三、主点偏置

​	公式6.1中的公式是假定图像平面的坐标原点在主点上。实际情况，图像平面的坐标原点可能在其他地方，一般在左上角。因此，一般情形的映射为：
$$
(\mathbf{X},\mathbf{Y},\mathbf{Z})^T \Rightarrow (f\mathbf{X}/\mathbf{Z}+p_x,f\mathbf{Y}/\mathbf{Z}+p_y)^T  \tag{6.4}
$$
​	其中，$(p_x,p_y)^T$是主点的坐标。用齐次式坐标表示为：
$$
\begin{pmatrix}\mathbf{X}\\\mathbf{Y}\\\mathbf{Z}\\\mathbf{1}\end{pmatrix} \Rightarrow \begin{pmatrix}f\mathbf{X}+\mathbf{Z}p_x\\f\mathbf{Y}+\mathbf{Z}p_y\\\mathbf{Z}\end{pmatrix} = \begin{bmatrix}f&&p_x&0\\&f&p_y&0\\&&1&0\end{bmatrix}\begin{pmatrix}\mathbf{X}\\\mathbf{Y}\\\mathbf{Z}\\\mathbf{1}\end{pmatrix} \tag{6.5}
$$
​	若记
$$
\mathbf{K} =\begin{bmatrix}f&&p_x\\&f&p_y\\&&1\end{bmatrix} \tag{6.6}
$$
​	则公式6.5的简洁形式如下：
$$
\mathbf{x}=\mathbf{K}[\mathbf{I}|\mathbf{0}]\mathbf{X}_{cam} \tag{6.7}
$$
​	其中$\mathbf{K}$为**摄像机标定矩阵**，$\mathbf{X}_{cam}$为摄像机坐标系。

四、摄像机旋转与平移

​	一般，空间点采用不同的欧式坐标系表示，称为**世界坐标系**。那么两个欧式坐标系之间怎么联系呢，这里便涉及到**2.4节变换的层次**里面的单应矩阵，即两个坐标系之间是通过旋转和平移联系的。我们假设$\tilde{\mathbf{X}}$是一个3维非齐次向量，表示世界坐标系中一点的坐标，而$\tilde{\mathbf{X}}_{cam}$是以摄像机坐标系来表示的同一点，那么我们可以记$\tilde{\mathbf{X}}_{cam} = \mathbf{R}(\tilde{\mathbf{X}}-\tilde{\mathbf{C}})$，其中$\tilde{\mathbf{C}}$表示摄像机中心在世界坐标系中的坐标，$\mathbf{R}$是一个表示摄像机坐标系方向的$3\times 3$旋转矩阵。该方程的齐次坐标如下：
$$
\mathbf{X}_{cam}=\begin{bmatrix}\mathbf{R} & -\mathbf{R}\tilde{\mathbf{C}} \\ \mathbf{0}^T & 1\end{bmatrix}\begin{pmatrix}\mathbf{X}\\\mathbf{Y}\\\mathbf{Z}\\\mathbf{1}\end{pmatrix} = \begin{bmatrix}\mathbf{R} & -\mathbf{R}\tilde{\mathbf{C}} \\ \mathbf{0}^T & 1\end{bmatrix}\mathbf{X} \tag{6.8}
$$
​	将上述公式和公式6.5相结合，可得：
$$
\mathbf{x}=\bf{}KR[I|-\tilde{\mathbf{C}}]X \tag{6.9}
$$
​	为方便起见，通常不显式地标出摄像机中心，而是把世界到图像的变换表示成$\tilde{\mathbf{X}}_{cam}=R\tilde{\mathbf{X}}+\mathbf{t}$。此时摄像机简化为
$$
\bf{}P=K[R|t] \tag{6.10}
$$
​	其中，根据式6.9，$\bf{}t=-R\tilde{\mathbf{C}}$。

五、CCD摄像机

​	我们之前假定的针孔摄像机模型图像坐标系是在两个轴向上具有相同的欧式坐标系。但是CCD摄像机的像素不一定是正方形。如果在$x$和$y$方向上图像坐标单位距离的像素数为$m_x$和$m_y$，那么由世界坐标系到像素坐标系的变换由公式6.6左乘一个附加的因子$diag(m_x,m_y,1)$而得到的。因此CCD摄像机的标定矩阵的一般形式是：
$$
\mathbf{K}=\begin{bmatrix}\alpha_x&&x_0\\&\alpha_y&y_0\\&&1\end{bmatrix} \tag{6.11}
$$
​	其中，$\alpha_x=fm_x、\alpha_y=fm_y$，像素的坐标原点为$(x_0,y_0)$。因为多一个尺度因子，所以CCD摄像机有10个自由度。

六、有限射影象机

​	为了增加一般性，我们可以考虑如下形式的标定矩阵
$$
\mathbf{K}=\begin{bmatrix}\alpha_x&s&x_0\\&\alpha_y&y_0\\&&1\end{bmatrix} \tag{6.12}
$$
​	增加的参数$s$称为**扭曲**参数，对于大多数标准的摄像机来说，其扭曲参数为零。但是在某些特殊情形，它可能取非零值。