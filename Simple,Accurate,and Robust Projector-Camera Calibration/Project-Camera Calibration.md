# 简单、精确并且高鲁棒性的投影仪-相机标定

## 参考

Simple,Accurate,and Robust Projector-Camera Calibration

## 简述

​	投影仪-相机成像系统是比较容易搭建的三维结构光感知系统。该系统可以生成高精度的三维点云，但是前提是精确获取投影仪和相机的内外参数。本文便提出了一种简单、精确并且高鲁棒性的投影仪-相机标定方法。首先，我们用相机拍摄空间中的棋盘格标定板，并提取出拍摄到的棋盘格标定板的角点，然后，我们需要使用投影仪把编码后的光(格雷码)依序投射在棋盘格标定板上，并对相机图片拍摄的投影仪的光编码进行解码。最后，我们要找到相机图片中棋盘格标定板的角点所对应的投影仪“图片”中的像素。这样就可以使投影仪“看到”标定板，或者说看到标定板上有效的特征点（角点）。这样便可以得到投影仪和相机之间的关系。

## 内容

​	通过对相机的每个像素进行光解码，我们可以得到每个相机像素点对应的投影仪像素点。最简单的想法是，直接把相机棋盘格图片上每个角点对应的相机像素点直接对应到其解出的投影仪编码位置上。然而这样做通常无法得到棋盘格角点在投影仪图片上的准确映射，原因如下：

1）我们相机上找到的特征点（棋盘格角点）通常是亚像素级的，而解码只能得到相机图片上每个像素对应的投影仪编码位置。

2）对于某些编码方法，如格雷码，只能对投影仪的每个像素进行编码，即解码后的精度也只能是像素级的。

3） 通常情况下，投影仪的分辨率会比相机低，这意味着，相机上相邻几行可能对应投影仪图片上同一行，相机上相邻几列可能对应投影仪图片上同一列。

4）对单个像素而言，解码可能存在误差或者解码结果是不确定的（即该点由于种种原因无法解码）。

如果刚好在角点位置处的解码被判断为不确定点，事实上这种情况非常有可能（稍后会介绍），会导致部分角点位置没有解码结果，从而不能被投影仪“看到”或者“看到”的角点误差特别大，导致标定结果误差很大甚至无法使用。

​	通过相机拍摄棋盘格的角点获取每个角点的局部单应性矩阵，然后通过单应性矩阵把相机图片上棋盘格角点映射到投影仪图片上，这样就可以得到棋盘格角点在投影仪图片上的准确成像位置，且每个角点在投影仪图片上的成像坐标是亚像素级的。

## 原理

![local homographies](https://github.com/N-January/paper-reading-DP/blob/master/Simple%2CAccurate%2Cand Robust Projector-Camera Calibration/picture/local homographies.png)



​	如图所示，captured image 表示的是相机图片，projected image 表示的是假想的投影仪图片。利用相机图片中每个角点附近的像素点集及其对应的解码坐标，计算一个局部单应性矩阵H，然后把相机图片上的角点P与单应性矩阵相乘，就可以得到棋盘格角点在投影仪图片上的成像位置q。需要注意的是，我们要对一幅棋盘格图片上的每个角点都单独计算一个局部单应性矩阵H，如图中所示，如果棋盘格上有n个角点，则每幅棋盘格图像要计算n个局部单应性矩阵。

​	局部单应性矩阵的计算方式如下，对相机图片上一个角点，假设其在邻域上有m个像素存在有效的解码坐标，则利用这m个像素点集{p}及其对应的投影仪图片像素坐标集{q}（解码结果），我们可以建立如下方程：（p和q均为齐次坐标）
$$
\hat{H}= argmin\sum_{\forall p}||q-Hp||^2
$$

$$
H\in \R,p=[x,y,1]^T,q=[col,row,1]^T
$$

​	即找到一个3x3的矩阵H，使得这m个有效像素点p乘上H后和实际的解码坐标q的距离和最小。其实这个很好理解，就是找到一个矩阵，使得角点附近每个像素点p经过转换后和其实际在投影仪图片上的真实值q误差最小。这个H就是我们要计算的局部单应性矩阵。

其中单应性矩阵求解公式如下：
$$
\bar{q}=\hat{H}\cdot\bar{p}
$$

## 结果

​	通过和其他方法得到的投影仪二次投影的误差，可以得到本方法的误差小，精度高。

## 结论

​	本文通过结构光中的格雷码的编解码得到的解码坐标以及相机图片中每个角点附近的像素点集群，求得局部单应性矩阵，然后通过单应性矩阵得到棋盘格角点在投影仪上的像素位置。该方法精度高，为亚像素级别；而且不受相机标定参数的影响，标定过程简单，鲁棒性高，方法不错。